{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Packages needed\n",
    " \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlalchemy as sa\n",
    "from sqlalchemy import create_engine as ce\n",
    "from datetime import *\n",
    "from tqdm import tqdm\n",
    "import scipy.stats as ss\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly    \n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add sme features that you want to check stability. \n",
    "features = [\"feature_1\",\n",
    "               \"feature_2\", \n",
    "               \"feature_3\", \n",
    "               \"feature_4\", \n",
    "               \"feature_5\", \n",
    "               \"feature_6\", \n",
    "               \"feature_7\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of all target metrics that migth be used for further analysis;  small letters\n",
    "\n",
    "targets = ['main_target_metric', \n",
    "           'target_metric_1', \n",
    "           'target_metric_2']           \n",
    "\n",
    "target = 'main_target_metric'                    # target metric that will be used by decision tree;  small letters\n",
    "binary_metric = 'binary_target_metric'\n",
    "\n",
    "clip_metric = 'yes'                              # Clip metric values : 'yes' or 'no'\n",
    "clip_metric_limit = [0, 3000]                    # Min, Max values to limit metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# unexpected_numeric_values = {'original' : 999999999.0, 'replace' : 999999.0}\n",
    "# unexpected_string_values = {'original' : '999999999.0', 'replace' : '999999.0'}\n",
    "# special_char = ['$', '&', '%']\n",
    "\n",
    "# There could be many different ways NAs could be present in dataset. All the following will be converted to numpy.nan\n",
    "nas_to_replace = ['NA', 'NULL', 'NUL', 'NaN', '[NA]', 'nan', 'NAN', ' ']\n",
    "\n",
    "# Identify datetime col, if prefix/postfix already known (and does not appear in any other type of feature name)\n",
    "# Any datetime feature name prefix/postfix except time_column\n",
    "datetime_cols_id = ['dt_'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = \"'2023-05-01'\"                         # Date is inclusive\n",
    "end_date = \"'2023-08-15'\"                           # Date is inclusive\n",
    "\n",
    "ip = 'xxx.xx.xxx.xxx'                               # IP address\n",
    "port = xxxx\n",
    "user = 'username'                                   # username\n",
    "pass_ai = 'password'                                # password user \n",
    "db = 'dbname'                                       # name of schema\n",
    "\n",
    "main_table = 'table_name'                           # name of table\n",
    "filter = \"isrelevant=1 and on_off = 0\"              # filter for table\n",
    "time_column = 'calltime'                            # column name in table for calltime\n",
    "granularity = 'week'                                # For week-wise ('week') or daily ('date') stability charts     \n",
    "\n",
    "dates_to_filter = \"('2022-05-01')\"                  # If some dates needs to be removed from data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Fetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data is fetched through following sql query\n",
    "\n",
    "query = \"Select \" + time_column + ','+','.join(features)+','+','.join(targets)+\" from \" + main_table + \" where \" + time_column + \" >= \" + start_date +\" and \" + time_column + \" <= \" + end_date +\" and \" + filter +\" and and \" +time_column+\" not in \"+dates_to_filter+\" ;\"\n",
    "print(query)\n",
    "\n",
    "ai_conn = ce('mysql://'+user+':'+pass_ai+'@'+ip+':'+str(port)+'/'+db)\n",
    "data = pd.read_sql(query,ai_conn)\n",
    "\n",
    "print(\"data fetched successfully : \", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change column names to lower case\n",
    "data = data.rename(columns = lambda x: x.lower())\n",
    "\n",
    "# replace desired values with NAs\n",
    "for col in data.columns:\n",
    "    data[col] = data[col].replace(nas_to_replace, np.nan)\n",
    "    \n",
    "# Clip metric if required\n",
    "if clip_metric == 'yes':\n",
    "    data[target] = data[target].astype(float).clip(clip_metric_limit[0], clip_metric_limit[1])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Stability plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join all datasets on a common index type column with all unique values\n",
    "final_data = data.copy()\n",
    "\n",
    "# Convert time column to datetime datatype\n",
    "final_data[time_column] = pd.to_datetime(final_data[time_column])\n",
    "\n",
    "# create a list of features without target metric and time column\n",
    "drop = [target, time_column]\n",
    "feature_list = final_data.drop(drop, axis=1).columns\n",
    "\n",
    "# Convert all data into object datatype\n",
    "for i in feature_list:\n",
    "    final_data[i] = final_data[i].astype(object)\n",
    "\n",
    "# create date and week columns \n",
    "\n",
    "final_data['date'] = final_data[time_column].dt.date\n",
    "final_data['week'] = final_data[time_column].dt.isocalendar().week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to convert figs plots into hml file\n",
    "\n",
    "def figures_to_html(figs, filename = 'dashboard.html'):\n",
    "    dashboard = open(filename, 'w')\n",
    "    dashboard.write(\"<html><head></head><body>\" + \"\\n\")\n",
    "    for fig in figs:\n",
    "        inner_html = fig.to_html().split('<body>')[1].split('</body>')[0]\n",
    "        dashboard.write(inner_html)\n",
    "    dashboard.write(\"</body>\")\n",
    "    \n",
    "fig_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating stability plots. \n",
    "# There are 3 plots in a single column. 1- Proportion of individual value 2- Granularity wise average target value 3- Granulairty wise rank of each value in feature\n",
    "\n",
    "# going through list of features one by one\n",
    "for j in tqdm(range(len(feature_list))):\n",
    "\n",
    "    # create a subplot with 1 row and 3 columns\n",
    "    fig = make_subplots(rows=1, cols=3, subplot_titles = [prefix + \"proportion\", prefix + \"average target\", prefix + \"rank\"])    \n",
    "    feature = feature_list[j]\n",
    "    \n",
    "    # Calculating proportion of each distinct value in feature\n",
    "    plotting_data = final_data.groupby([granularity, feature]).size().unstack()\n",
    "    week_vols = []\n",
    "    for i in range(len(plotting_data)):\n",
    "        week_vols.append(plotting_data.iloc[i].sum())\n",
    "        plotting_data.iloc[i] = plotting_data.iloc[i]/week_vols[i] * 100\n",
    "\n",
    "    # Filling NaNs to 0 in plotting data\n",
    "    plotting_data = plotting_data.fillna(0)\n",
    "\n",
    "    # Creating plots and saving in fig variable\n",
    "    for i, col in enumerate(plotting_data.columns):\n",
    "            fig.add_trace(go.Bar(name = col, x=plotting_data.index, y=plotting_data[col]), row=1, col=1)\n",
    "\n",
    "    # Calculating average target metric for each distinct feature value\n",
    "    plotting_data = final_data.groupby([granularity, feature])[target].mean().unstack()\n",
    "    plotting_data = plotting_data.fillna(0)\n",
    "    for i, col in enumerate(plotting_data.columns):\n",
    "        fig.add_trace(go.Scatter(x = plotting_data.index, y=plotting_data[col], mode='lines+markers', name=col), row=1, col=2)\n",
    "\n",
    "    # Calculating rank (based on average target metric value) for each distinct feature value\n",
    "    plotting_data = final_data.groupby([granularity, feature])[target].mean().unstack()\n",
    "    plotting_data = plotting_data.fillna(0)\n",
    "    for i in range(len(plotting_data)):\n",
    "        plotting_data.iloc[i] = ss.rankdata(plotting_data.iloc[i])\n",
    "\n",
    "    for i, col in enumerate(plotting_data.columns):\n",
    "        fig.add_trace(go.Scatter(x = plotting_data.index, y=plotting_data[col], mode='lines+markers', name=col), row=1, col=3)\n",
    "\n",
    "\n",
    "    fig.update_xaxes(title_text=granularity)\n",
    "    fig.update_yaxes(title_text=\"Proportion\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Average \"+target, row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"Rank\", row=3, col=1)\n",
    "    fig.update_layout(title=feature)\n",
    "    fig.update_layout(barmode='stack')\n",
    "    \n",
    "    fig_list.append(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stability plots are stored as html file on current working directory\n",
    "figures_to_html(fig_list,'./features_stability.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
